{"cells":[{"cell_type":"markdown","metadata":{"id":"2wrQHvdptIM1"},"source":["# Data Preparation - Preprocessing\n","Shpaner, Leonid  \n","Robinson, Christopher  \n","Luis-Estrada, Jose  "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3028,"status":"ok","timestamp":1658776723299,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"cA6mxRBaaMMH","outputId":"bb57b95f-8ada-49ea-c427-daf4f57ccb80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1658776723300,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"n5u12S2YagM-","outputId":"9d9e7b9e-431e-4cb2-807b-f4f90136f307"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shared drives/Capstone - Best Group/navigating_crime/Code Library\n"]}],"source":["%cd /content/drive/Shared drives/Capstone - Best Group/navigating_crime/Code Library"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1422,"status":"ok","timestamp":1658776724716,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"MC6w_sr7erj_"},"outputs":[],"source":["####################################\n","## import the requisite libraries ##\n","####################################\n","import os\n","import csv\n","import pandas as pd\n","import numpy as np\n","\n","# import data_types .py file created for inspecting data types\n","from functions import data_types\n","\n","# library for one-hot encoding\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# import library from sci-kit learn for splitting the data\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1658776724725,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"s_fQsmPYeuyE","outputId":"0ef5ee5d-95ed-47ed-a0e4-55d3e21bc81d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/Shared drives/Capstone - Best Group/navigating_crime/Code Library'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["# check current working directory\n","current_directory = os.getcwd()\n","current_directory"]},{"cell_type":"markdown","metadata":{"id":"e29UeHnqpGv3"},"source":["### Assign Paths to Folders"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1658776724728,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"PJGujjjm_Voj"},"outputs":[],"source":["# path to the data file\n","data_path1 = '/content/drive/Shareddrives/Capstone - Best Group/Final_Data_20220719/LA_Streets_with_Crimes_By_Division.csv'\n","\n","# path to data folder\n","data_path2 = '/content/drive/Shareddrives/Capstone - Best Group/navigating_' \\\n","           + 'crime/Data Folder/'\n","\n","# path to the image library\n","image_path = '/content/drive/Shareddrives/Capstone - Best Group/navigating_' \\\n","           + 'crime/Image Folder'        "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"elapsed":8856,"status":"ok","timestamp":1658776733554,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"MQT9GLXfeyFY","outputId":"bbb27402-6299-49f9-d803-33c879d69ac0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              Shape  Join_Count  TARGET_FID  \\\n","OBJECTID                                                                      \n","18            (-13168057.17375, 3992141.1804500036)           1          18   \n","36                  (-13180677.51995, 4031566.0669)           1          36   \n","37                  (-13180677.51995, 4031566.0669)           1          36   \n","44        (-13160890.369035002, 4035687.0216437643)           1          43   \n","56             (-13165346.8195, 4030644.1469999994)           1          55   \n","\n","          Join_Count_1  TARGET_FID_1  JOIN_FID FullName       Type Elevation  \\\n","OBJECTID                                                                       \n","18                   1            18        -1      NaN      Alley   Unknown   \n","36                   1            36        -1      NaN  Secondary   Surface   \n","37                   1            37        -1      NaN  Secondary   Surface   \n","44                   1            44        -1      NaN      Minor   Surface   \n","56                   1            56        -1      NaN  Secondary   Surface   \n","\n","          Surface  ...      LAT       LON  OBJECTID_1       APREC  PREC  \\\n","OBJECTID           ...                                                    \n","18        Unknown  ...  33.7261 -118.2907        20.0      HARBOR   5.0   \n","36          Paved  ...  34.0205 -118.4040        17.0     PACIFIC  14.0   \n","37          Paved  ...  34.0205 -118.4040        17.0     PACIFIC  14.0   \n","44          Paved  ...  34.0509 -118.2265        11.0  HOLLENBECK   4.0   \n","56          Paved  ...  34.0138 -118.2663        16.0      NEWTON  13.0   \n","\n","                AREA_1      PERIMETER SHAPE_Leng Shape_Length_1 Shape_Length  \n","OBJECTID                                                                      \n","18        8.928780e+08  272451.139908   0.807721       0.807721   120.220887  \n","36        7.176129e+08  246934.321606   0.757182       0.757182    15.473452  \n","37        7.176129e+08  246934.321606   0.757182       0.757182    15.473452  \n","44        4.330323e+08  111317.952873   0.329096       0.329096   118.766240  \n","56        2.723760e+08   81476.922847   0.241128       0.241128     9.731604  \n","\n","[5 rows x 80 columns]"],"text/html":["\n","  <div id=\"df-a019f2e7-49c5-43a0-86e5-2f5efbe74de5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Shape</th>\n","      <th>Join_Count</th>\n","      <th>TARGET_FID</th>\n","      <th>Join_Count_1</th>\n","      <th>TARGET_FID_1</th>\n","      <th>JOIN_FID</th>\n","      <th>FullName</th>\n","      <th>Type</th>\n","      <th>Elevation</th>\n","      <th>Surface</th>\n","      <th>...</th>\n","      <th>LAT</th>\n","      <th>LON</th>\n","      <th>OBJECTID_1</th>\n","      <th>APREC</th>\n","      <th>PREC</th>\n","      <th>AREA_1</th>\n","      <th>PERIMETER</th>\n","      <th>SHAPE_Leng</th>\n","      <th>Shape_Length_1</th>\n","      <th>Shape_Length</th>\n","    </tr>\n","    <tr>\n","      <th>OBJECTID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>18</th>\n","      <td>(-13168057.17375, 3992141.1804500036)</td>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>Alley</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>...</td>\n","      <td>33.7261</td>\n","      <td>-118.2907</td>\n","      <td>20.0</td>\n","      <td>HARBOR</td>\n","      <td>5.0</td>\n","      <td>8.928780e+08</td>\n","      <td>272451.139908</td>\n","      <td>0.807721</td>\n","      <td>0.807721</td>\n","      <td>120.220887</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>(-13180677.51995, 4031566.0669)</td>\n","      <td>1</td>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>36</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>Secondary</td>\n","      <td>Surface</td>\n","      <td>Paved</td>\n","      <td>...</td>\n","      <td>34.0205</td>\n","      <td>-118.4040</td>\n","      <td>17.0</td>\n","      <td>PACIFIC</td>\n","      <td>14.0</td>\n","      <td>7.176129e+08</td>\n","      <td>246934.321606</td>\n","      <td>0.757182</td>\n","      <td>0.757182</td>\n","      <td>15.473452</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>(-13180677.51995, 4031566.0669)</td>\n","      <td>1</td>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>37</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>Secondary</td>\n","      <td>Surface</td>\n","      <td>Paved</td>\n","      <td>...</td>\n","      <td>34.0205</td>\n","      <td>-118.4040</td>\n","      <td>17.0</td>\n","      <td>PACIFIC</td>\n","      <td>14.0</td>\n","      <td>7.176129e+08</td>\n","      <td>246934.321606</td>\n","      <td>0.757182</td>\n","      <td>0.757182</td>\n","      <td>15.473452</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>(-13160890.369035002, 4035687.0216437643)</td>\n","      <td>1</td>\n","      <td>43</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>Minor</td>\n","      <td>Surface</td>\n","      <td>Paved</td>\n","      <td>...</td>\n","      <td>34.0509</td>\n","      <td>-118.2265</td>\n","      <td>11.0</td>\n","      <td>HOLLENBECK</td>\n","      <td>4.0</td>\n","      <td>4.330323e+08</td>\n","      <td>111317.952873</td>\n","      <td>0.329096</td>\n","      <td>0.329096</td>\n","      <td>118.766240</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>(-13165346.8195, 4030644.1469999994)</td>\n","      <td>1</td>\n","      <td>55</td>\n","      <td>1</td>\n","      <td>56</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","      <td>Secondary</td>\n","      <td>Surface</td>\n","      <td>Paved</td>\n","      <td>...</td>\n","      <td>34.0138</td>\n","      <td>-118.2663</td>\n","      <td>16.0</td>\n","      <td>NEWTON</td>\n","      <td>13.0</td>\n","      <td>2.723760e+08</td>\n","      <td>81476.922847</td>\n","      <td>0.241128</td>\n","      <td>0.241128</td>\n","      <td>9.731604</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 80 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a019f2e7-49c5-43a0-86e5-2f5efbe74de5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a019f2e7-49c5-43a0-86e5-2f5efbe74de5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a019f2e7-49c5-43a0-86e5-2f5efbe74de5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["# read in the csv file to a dataframe using pandas\n","df = pd.read_csv(data_path1, low_memory=False).set_index('OBJECTID')\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1658776733556,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"j-tKFJ0SwiGF","outputId":"666b2f8e-4295-4fbe-ed4d-471eb097ac20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Shape', 'Join_Count', 'TARGET_FID', 'Join_Count_1', 'TARGET_FID_1',\n","       'JOIN_FID', 'FullName', 'Type', 'Elevation', 'Surface', 'Status',\n","       'DrivingDir', 'From_L', 'From_R', 'To_L', 'To_R', 'Parity_L',\n","       'Parity_R', 'StPreDir', 'StPreMod', 'StPreType', 'StArticle', 'StName',\n","       'StPostType', 'StPostDir', 'StPostMod', 'Zip_L', 'Zip_R', 'LCity_L',\n","       'LCity_R', 'NameCat_L', 'NameCat_R', 'Accuracy', 'Jurisdiction',\n","       'Source', 'SourceID', 'UpdateDate', 'MSAG_LCity', 'MSAG_RCity',\n","       'MSAG_LESN', 'MSAG_RESN', 'Crime_Cost', 'StreetOID', 'Field1', 'DR_NO',\n","       'Date_Rptd', 'DATE_OCC', 'TIME_OCC', 'AREA', 'AREA_NAME', 'Rpt_Dist_No',\n","       'Part_1_2', 'Crm_Cd', 'Crm_Cd_Desc', 'Mocodes', 'Vict_Age', 'Vict_Sex',\n","       'Vict_Descent', 'Premis_Cd', 'Premis_Desc', 'Weapon_Used_Cd',\n","       'Weapon_Desc', 'Status_1', 'Status_Desc', 'Crm_Cd_1', 'Crm_Cd_2',\n","       'Crm_Cd_3', 'Crm_Cd_4', 'LOCATION', 'Cross_Street', 'LAT', 'LON',\n","       'OBJECTID_1', 'APREC', 'PREC', 'AREA_1', 'PERIMETER', 'SHAPE_Leng',\n","       'Shape_Length_1', 'Shape_Length'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}],"source":["# show the columns of the dataframe for inspection\n","df.columns"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1658776733557,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"adwB_kfJw6j7","outputId":"a3ee9377-200f-4ff3-f70e-493c6d047f8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(183362, 80)"]},"metadata":{},"execution_count":8}],"source":["# re-inspect the shape of the dataframe. This is also done on EDA file.\n","df.shape"]},{"cell_type":"markdown","metadata":{"id":"c_HKLJqpQd8t"},"source":["## Introduction\n","\n","The data is ingested from a shared google drive path and in its raw form, contains 183,362 rows and 80 columns. The preprocessing stage begins by inspecting each column's data types along with its respective null values."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1150,"status":"ok","timestamp":1658776734695,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"JAwSifRnLpqi"},"outputs":[],"source":["# run the python file created for showing columns, data types, and their\n","# respective null counts (this was imported as a library at the top of this nb)\n","dtypes = data_types(df)\n","pd.set_option('display.max_rows', None)\n","dtypes = dtypes.sort_values(by='# of Nulls', ascending=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1658776734697,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"lpla087g0m12","outputId":"c02e3e92-ad6a-4c82-fce3-fad3729af919"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Column/Variable Data Type  # of Nulls  Percent Null\n","18        StPreDir    object       83241          45.0\n","69    Cross_Street    object       74575          41.0\n","23      StPostType    object        6189           3.0\n","61     Weapon_Desc    object        3274           2.0\n","60  Weapon_Used_Cd   float64        3274           2.0\n","6         FullName    object        1357           1.0\n","22          StName    object        1357           1.0\n","75          AREA_1   float64         686           0.0\n","76       PERIMETER   float64         686           0.0\n","74            PREC   float64         686           0.0\n","73           APREC    object         686           0.0\n","72      OBJECTID_1   float64         686           0.0\n","54         Mocodes    object         219           0.0\n","57    Vict_Descent    object         171           0.0\n","56        Vict_Sex    object         167           0.0\n","33    Jurisdiction    object          28           0.0"],"text/html":["\n","  <div id=\"df-faa6129f-cab6-40aa-b583-98501c066fcf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Column/Variable</th>\n","      <th>Data Type</th>\n","      <th># of Nulls</th>\n","      <th>Percent Null</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>18</th>\n","      <td>StPreDir</td>\n","      <td>object</td>\n","      <td>83241</td>\n","      <td>45.0</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>Cross_Street</td>\n","      <td>object</td>\n","      <td>74575</td>\n","      <td>41.0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>StPostType</td>\n","      <td>object</td>\n","      <td>6189</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>Weapon_Desc</td>\n","      <td>object</td>\n","      <td>3274</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>Weapon_Used_Cd</td>\n","      <td>float64</td>\n","      <td>3274</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>FullName</td>\n","      <td>object</td>\n","      <td>1357</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>StName</td>\n","      <td>object</td>\n","      <td>1357</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>AREA_1</td>\n","      <td>float64</td>\n","      <td>686</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>PERIMETER</td>\n","      <td>float64</td>\n","      <td>686</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>PREC</td>\n","      <td>float64</td>\n","      <td>686</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>APREC</td>\n","      <td>object</td>\n","      <td>686</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>OBJECTID_1</td>\n","      <td>float64</td>\n","      <td>686</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>Mocodes</td>\n","      <td>object</td>\n","      <td>219</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Vict_Descent</td>\n","      <td>object</td>\n","      <td>171</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>Vict_Sex</td>\n","      <td>object</td>\n","      <td>167</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Jurisdiction</td>\n","      <td>object</td>\n","      <td>28</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa6129f-cab6-40aa-b583-98501c066fcf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-faa6129f-cab6-40aa-b583-98501c066fcf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-faa6129f-cab6-40aa-b583-98501c066fcf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["# here only the top null columns are subset\n","# a good amount of these columns are to be subsequently removed\n","dat_typ = dtypes[(dtypes['Percent Null']<84) & (dtypes['# of Nulls']>0)]\n","\n","# any column with '_L' and '_R' is of no interest and will be dropped\n","dat_typ = dat_typ[dat_typ['Column/Variable'].str.contains('_L')==False]\n","dat_typ = dat_typ[dat_typ['Column/Variable'].str.contains('_R')==False]\n","dat_typ\n","\n","# object types are typically removed for ML processing, but some imputation\n","# may be necessary, which is why they are examined prior"]},{"cell_type":"markdown","metadata":{"id":"kSpKiHpz5gfz"},"source":["For example, there are 3,274 missing values for weapon description. Imputation is necessary to properly assign the corresponding numerical value to the corresponding weapons used code, which is also missing 3,274 observations.  \n","\n","The victim descent column only has 171 missing values, the rows corresponding to these values can be dropped, but they are instead imputed with 'Unknown' since the ethnicities here remain unknown.  \n","\n","The same holds true for victim's sex, where there exist 167 missing values. \n","\n","Ethnicity and age are important features which will be numericized and adapted for use with machine learning. Jurisdiction and other string columns presented herein will be subsequently omitted from the development (modeling) set."]},{"cell_type":"markdown","metadata":{"id":"1qpNqDa27yf1"},"source":["## Imputation Strategies\n","\n","Weapons used in crimes contain useful information, and the rows of missing data presented therein are imputed by a value of 500, corresponding to 'unknown' in the data dictionary. Similarly, the missing values in victim's sex and ethnicity, respectively, are imputed by a categorical value of \"X,\" for \"unknown.\" The 211 missing values contained in the zip code column are dropped since they cannot be logically imputed."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":713,"status":"ok","timestamp":1658776735398,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"Zyr224Gp3jzi"},"outputs":[],"source":["# Since the code for unknown weapons is 500, missing values for 'Weapon_Used_Cd' \n","# where 'Weapon_Desc' is 'UNKNOWN WEAPON/OTHER WEAPON' will be 500.\n","# However, since missing values in one column correspond to the other, \n","# missing values in 'Weapon_Desc' will need to be imputed first with\n","# 'UNKNOWN WEAPON/OTHER WEAPON'\n","\n","# impute missing weapon descriptions\n","df['Weapon_Desc'] = df['Weapon_Desc'].fillna('UNKNOWN WEAPON/OTHER WEAPON')\n","\n","# impute missing 'Weapon_Used_Cd' with 500 for reasons discussed above.\n","df['Weapon_Used_Cd'] = df['Weapon_Used_Cd'].fillna(500)\n","\n","# impute missing values for victim's gender with 'X,' since this corresponds to\n","# 'Unknown' in the data dictionary\n","df['Vict_Sex'] = df['Vict_Sex'].fillna('X')\n","\n","# impute missing values for victim's race with 'X,' since this corresponds to\n","# 'Unknown' in the data dictionary\n","df['Vict_Descent'] = df['Vict_Descent'].fillna('X')\n","\n","# Since there are only 211 rows with missing zip codes, those rows are dropped\n","df.dropna(subset=['Zip_R'], inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"LWyFcEuVQmIv"},"source":["## Feature Engineering\n","\n","There exist two date columns, date reported and date occurred, of which only the latter is used for extracting the year and month into two new columns, respectively, since a date object by itself cannot be used in a machine learning algorithm. In addition, descriptions of street premises are first converted into lower case strings within the column and subsequently encoded into separate binarized columns. Similarly, new columns for time (derived from military time) and city neighborhoods (derived from area) are encoded into binarized columns, respectively. \n","\n","More importantly, the target column (Crime_Code) is defined by the values in the 'Crm_Cd' column where 0 is for any crime that ranges from 1-499 (most severe) and 1 is for any crime above 500 (less severe). \n","# anything above 500 is less severe"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":46547,"status":"ok","timestamp":1658776781938,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"nzxn9lX_mZKE"},"outputs":[],"source":["# create new column only for year of 'Date_Occurred'\n","df['Year'] = pd.DatetimeIndex(df['DATE_OCC']).year\n","\n","# create new column for month of year\n","df['Month'] = pd.DatetimeIndex(df['DATE_OCC']).month\n","\n","# bin the ages using pd.cut() function\n","df['age_bin'] = pd.cut(df['Vict_Age'],\n","                            bins=[0, 5, 10, 15, 20, 25, 30,\n","                                  35, 40, 45, 50, 55, 60, 65,\n","                                  70, 75, 80, 85, 90, 95, 100,\n","                                  105, 110, 115, 120],\n","                            labels=['0-5', '5-10', '10-15', '15-20', '20-25',\n","                                    '25-30', '30-35', '35-40', '40-45', '45-50',\n","                                    '50-55', '55-60', '60-65', '65-70', '70-75',\n","                                    '75-80', '80-85', '85-90', '90-95', '95-100', \n","                                    '100-105', '105-110', '110-115', '115-120'])\n","\n","# binarize the 'Crm_Cd' column; this is the target column\n","# 0 is for any crime that ranges 1-499 (most severe)\n","# anything above 500 is less severe\n","df['Crime_Code'] = df['Crm_Cd'].apply(lambda value: '1' if value <= 499 else \\\n","                                     ('0' if value >= 500 else '2'))\n","\n","# re-categorize ground truth as serious vs. not serious crimes where serious \n","# crimes are '1' and less serious crimes are '0'\n","df['crime_severity'] = df['Crime_Code'].map({'0':'Less Serious', \n","                                                  '1':'More Serious'\n","                                                  }\n","                                                 )\n","\n","# creating a new column of premises types by renaming the premises types to lower\n","# case characters and eliminating spaces between words\n","df['Premises'] = df['Premis_Desc'].replace({'STREET': 'Street',\n","                                            'SIDEWALK': 'Sidewalk',\n","                                            'PARKING LOT': 'Parking_Lot',\n","                                            'ALLEY': 'Alley',\n","                                            'DRIVEWAY': 'Driveway',\n","                                            'PARK/PLAYGROUND': 'Park_Playground',\n","                                            'VACANT LOT': 'Vacant_Lot',\n","                                            'TUNNEL': 'Tunnel',\n","                                            'PEDESTRIAN OVERCROSSING': \\\n","                                            'Pedestrian_Overcrossing'\n","                                            }\n","                                           )\n","\n","# replace strings with spaces of neighborhoods within 'AREA_NAME' to \n","# strings without spaces by replacing the space with an underscore since \n","# this is a more acceptable format for a final dataframe\n","df['AREA_NAME'] = df['AREA_NAME'].replace({'77th Street': '77th_Street',\n","                                           'N Hollywood': 'N_Hollywood',\n","                                           'Van Nuys': 'Van_Nuys',\n","                                           'West Valley': 'West_Valley',\n","                                           'West LA': 'West_LA'\n","                                           }\n","                                          )\n","\n","# creating instance of one-hot-encoder using pd.get_dummies\n","# perform one-hot encoding on 'Vict_Descent' column \n","premise_encode = pd.get_dummies(df['Premises'])\n","# join these new columns back to the original dataframe\n","df = premise_encode.join(df)\n","\n","def applyFunc(s):\n","    if s==0:\n","        return 'Midnight'\n","    elif s<=1159:\n","        return 'Morning'\n","    elif s>=1200 and s<=1800:\n","        return 'Afternoon'\n","    elif s>=1800 and s<=2200:\n","        return 'Evening'\n","    elif s>2200:\n","        return 'Night'\n","\n","df['Time_of_Day'] = df['TIME_OCC'].apply(applyFunc)\n","\n","# dummy encode military time into 'Morning', 'Afternoon', 'Evening', 'Night',\n","# and 'Midnight' time of day strings, respectively, making them their own\n","# separate and distinct columns\n","military_encode = pd.get_dummies(df['Time_of_Day'])\n","df = military_encode.join(df)\n","\n","# dummy encode area names into their own separate and distinct columns\n","area_encode = pd.get_dummies(df['AREA_NAME'])\n","df = area_encode.join(df)"]},{"cell_type":"markdown","metadata":{"id":"SAis6fIxRGJs"},"source":["## Reclassifying Useful Categorical Features\n","\n","Gender and ethnicity are critical factors in making informed decisions about crime. New columns are created for both variables to better represent their characteristics. For example, unidentified genders are replaced with unknowns, and one-letter abbreviations for victim descent are re-categorized into full-text ethnicity descriptions from the city of Los Angeles' data dictionary."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11104,"status":"ok","timestamp":1658776793013,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"mNBgSDGWRCdY"},"outputs":[],"source":["# narrow down victim sex column to three categories (M, F, X=Unknown). Currently,\n","# there are four, with \"H\" presented. \"H\" is re-categorized to \"X\" since it is not\n","# in the data dictionary, and thus, remains unknown.\n","df['Victim_Sex'] = df['Vict_Sex'].map({'F':'F', 'H':'X', 'M':'M', 'X':'X'})\n","df['Gender'] = df['Victim_Sex'].map({'F':1, 'M':2, 'X':3})\n","\n","# reclassify letters in victim description back to full race description from\n","# data dictionary nomenclature and add as new column; this will be helpful for \n","# additional EDA post pre-processing.\n","df['Victim_Desc'] = df['Vict_Descent'].map({'A':'Other Asian', 'B':'Black', 'C':\n","                                         'Chinese', 'D': 'Cambodian', 'F':\n","                                         'Filipino', 'G': 'Guamanian', 'H':\n","                                         'Hispanic/Latin/Mexican', 'I':\n","                                         'American Indian/Alaskan Native', 'J':\n","                                         'Japanese', 'K': 'Korean', 'L': 'Laotian',\n","                                         'O': 'Other', 'P': 'Pacific Islander',\n","                                         'S': 'Samoan', 'U': 'Hawaiian', 'V':\n","                                         'Vietnamese', 'W': 'White', 'X': 'Unknown',\n","                                         'Z': 'Asian Indian'\n","                                         }\n","                                         )\n","\n","# write out the preliminarily preprocessed df to new .csv file\n","df.to_csv('/content/drive/Shareddrives/Capstone - Best Group/Final_Data_20220719'\n","         +'/df.csv')"]},{"cell_type":"markdown","metadata":{"id":"jWlnxLcjW9HO"},"source":["## Remove Columns Not Used for Model Development (Exclusion Criteria)\n"," \n","Any columns with all null rows and object data types are immediately dropped from the dataset, but cast into a new dataframe for posterity. \n","\n","Furthermore, only data from the year 2022 is included, since older retrospective data does not represent an accurate enough depiction of crime in the city of Los Angeles. Longitude and latitude columns are dropped since city neighborhood columns take their place for geographic information.  Moreover, columns like retained joins, identifications, report numbers, and categorical information encoded to the original dataframe are omitted from this dataframe. Columns that only present one unique value (Pedestrian Overcrossing and Tunnel) are removed. Lastly, any column (military time) that presents over and above the pearson correlation threshold of 0.75 is dropped to avoid between-predictor collinearity; all numeric values in the dataframe are cast to integer type formatting.\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":899,"status":"ok","timestamp":1658776793867,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"LI0FYwufmdJo","outputId":"2c34ce74-ac2b-4567-dc0a-f379857b7d79"},"outputs":[{"output_type":"stream","name":"stdout","text":["The following columns intersect as being objects and being null: ['MSAG_LCity' 'MSAG_RCity' 'StPostDir' 'StPreMod'] \n","\n","Removed Fully Null columns:\n","\tStPostMod\n","\tStPreMod\n","\tCrm_Cd_4\n","\tStPostDir\n","\tMSAG_RESN\n","\tMSAG_LCity\n","\tMSAG_RCity\n","\tMSAG_LESN\n","\n","Removed string and object columns:\n","\tStPreMod\n","\tStPostDir\n","\tMSAG_LCity\n","\tMSAG_RCity\n","\tStPreType\n","\tStArticle\n","\tStPreDir\n","\tCross_Street\n","\tStPostType\n","\tWeapon_Desc\n","\tParity_L\n","\tNameCat_L\n","\tNameCat_R\n","\tParity_R\n","\tFullName\n","\tStName\n","\tAPREC\n","\tMocodes\n","\tVict_Descent\n","\tVict_Sex\n","\tJurisdiction\n","\tLCity_R\n","\tLCity_L\n","\tPremis_Desc\n","\tLOCATION\n","\tStatus_Desc\n","\tCrm_Cd_Desc\n","\tStatus_1\n","\tShape\n","\tSourceID\n","\tType\n","\tElevation\n","\tSurface\n","\tStatus\n","\tDrivingDir\n","\tSource\n","\tUpdateDate\n","\tDate_Rptd\n","\tDATE_OCC\n","\tAREA_NAME\n","\n","Removed Latitude and Longtitude Columns\n","\tLAT\n","\tLON\n","\n","Removed Extraneous Crm_Cd Columns:\n","\tCrm_Cd\n","\tCrm_Cd_1\n","\tCrm_Cd_2\n","\tCrm_Cd_3\n","\n","\n","Removed Columns Persisting After JOIN:\n","\tJoin_Count\n","\tJoin_Count_1\n","\tJOIN_FID\n","\tPremis_Cd\n","\tOBJECTID_1\n","\tPremises\n","\tTime_of_Day\n","\n","Removed columns with only one unique value:\n","\tPedestrian_Overcrossing\n","\tTunnel\n","\n","These are the columns we should drop: ['TIME_OCC']\n"]}],"source":["# make a unique list of cols to remove that are completely missing\n","cols_to_remove_null = dtypes[(dtypes[\"Percent Null\"] == 100)] \\\n","                            ['Column/Variable'].unique()\n","\n","# make a unique list of cols to remove that are non-numeric\n","cols_to_remove_string = dtypes[(dtypes[\"Data Type\"] == 'object')] \\\n","                              ['Column/Variable'].unique()\n","\n","intersect = np.intersect1d(cols_to_remove_null, cols_to_remove_string)\n","print('The following columns intersect as being objects and being null:',\n","      intersect, '\\n')\n","\n","# Since these columns exist as objects too, they can be removed from the\n","# list of nulls such that they are not doubled up between the two.'\n","refined_null = [x for x in cols_to_remove_null if x not in cols_to_remove_string]\n","\n","# set-up new df without dropped columns (dataframe used later for modeling)\n","df_prep = df.drop(columns=refined_null) \n","\n","# Subset dataframe for observations only taking place in year 2022\n","df_prep = df_prep[df_prep['Year']==2022]\n","\n","print('Removed Fully Null columns:')\n","for c in cols_to_remove_null:\n","    print(f'\\t{c}')\n","print()\n","\n","# these columns are to be removed b/c they are object datatypes \n","# (i.e., free text, strings)\n","df_prep = df_prep.drop(columns=cols_to_remove_string)\n","\n","print('Removed string and object columns:')\n","for c in cols_to_remove_string:\n","    print(f'\\t{c}')\n","\n","# drop latitude & longitude columns; they will not be used to inform ML model(s)\n","print()\n","print('Removed Latitude and Longtitude Columns')\n","for col in df_prep.columns:\n","    if 'LAT' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","    elif 'LON' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","\n","# drop any additional crime code columns, since only Crm_Cd without number\n","# following it will be used as target\n","print()\n","print('Removed Extraneous Crm_Cd Columns:')\n","for col in df_prep.columns:\n","    if 'Crm_Cd' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","print()\n","\n","# drop any columns that persisted after join or feature engineering\n","print()\n","print('Removed Columns Persisting After JOIN:')\n","\n","for col in df_prep.columns:\n","    if 'JOIN_' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","    elif 'Join_' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","    elif 'OBJECTID' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","    elif 'Premis' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","    elif 'Time' in col:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')   \n","\n","# removed 'Victim_Sex' column because numericized as new 'Gender' column\n","# removed 'Victim_Desc' (ethnicity) since these cannot be numerically \n","# classified without introducing bias\n","\n","# drop any columns with '_L' or '_R' nomenclature since these are positional\n","# street indexes which are used to compile other location-based information\n","\n","# drop the 'DR_NO' column since these are associated with records\n","df_prep = df_prep.drop(columns=['From_L', 'From_R', 'To_L', 'To_R', 'Zip_L', \n","                                'Zip_R', 'SHAPE_Leng', 'Shape_Length_1',\n","                                'Shape_Length', 'DR_NO', 'TARGET_FID', 'age_bin',\n","                                'TARGET_FID_1', 'Accuracy', 'Crime_Cost',\n","                                'StreetOID', 'Field1', 'AREA', 'AREA_1', \n","                                'Part_1_2', 'Weapon_Used_Cd', 'PREC', 'Year',\n","                                'PERIMETER', 'Victim_Sex', 'Victim_Desc',\n","                                'Rpt_Dist_No', 'crime_severity'])\n","\n","print()\n","print('Removed columns with only one unique value:')\n","for col in df_prep:\n","    # remove any columns that have only one unique value in the data\n","    if df_prep[col].nunique() == 1:\n","        df_prep = df_prep.drop(columns=col)\n","        print(f'\\t{col}')\n","\n","# identify and drop any columns exceeding a correlation threshold of 0.75\n","corr_df = df_prep.reset_index(drop=True) # omit index by subsetting in new df\n","corr_matrix = corr_df.corr().abs()\n","\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","\n","# Find index of feature columns with correlation greater >= 0.75\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n","# Drop features exceeding a correlation threshold of 0.75\n","df_prep = df_prep.drop(corr_df[to_drop], axis=1)\n","print()\n","print('These are the columns we should drop: %s'%to_drop)\n","\n","# cast all numeric variables in preprocessed dataset to integers\n","df_prep = df_prep.astype(int)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1658776793870,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"yAVkY5HVIKh8","outputId":"9b64b15c-2d80-4891-823d-bf5bb320abf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Development Data Column List: \n","\n","77th_Street\n","Central\n","Devonshire\n","Foothill\n","Harbor\n","Hollenbeck\n","Hollywood\n","Mission\n","N_Hollywood\n","Newton\n","Northeast\n","Olympic\n","Pacific\n","Rampart\n","Southeast\n","Southwest\n","Topanga\n","Van_Nuys\n","West_LA\n","West_Valley\n","Wilshire\n","Afternoon\n","Evening\n","Morning\n","Night\n","Alley\n","Driveway\n","Park_Playground\n","Parking_Lot\n","Sidewalk\n","Street\n","Vacant_Lot\n","Vict_Age\n","Month\n","Crime_Code\n","Gender\n","\n","There are 42072 rows and 36 columns in the development set.\n"]}],"source":["# describe the new preprocessed dataset as the development set and list its cols\n","development_cols = df_prep.columns.to_list()\n","print('Development Data Column List:', '\\n')\n","for x in development_cols:\n","    print(x)\n","print()\n","print('There are', df_prep.shape[0], 'rows and', df_prep.shape[1], \n","      'columns in the development set.')"]},{"cell_type":"markdown","source":["Data types are examined once more on this preprocessed dataset to ensure that all data types are integers and no columns remain null. At this stage, there are 42,072 rows and 38 columns. "],"metadata":{"id":"X67R9QmZflm1"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1658776793872,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"KhsgyugBb669","outputId":"51698ba0-a8ea-48bd-946c-2e7c9490f974"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Column/Variable Data Type  # of Nulls  Percent Null\n","0       77th_Street     int64           0           0.0\n","1           Central     int64           0           0.0\n","2        Devonshire     int64           0           0.0\n","3          Foothill     int64           0           0.0\n","4            Harbor     int64           0           0.0\n","5        Hollenbeck     int64           0           0.0\n","6         Hollywood     int64           0           0.0\n","7           Mission     int64           0           0.0\n","8       N_Hollywood     int64           0           0.0\n","9            Newton     int64           0           0.0\n","10        Northeast     int64           0           0.0\n","11          Olympic     int64           0           0.0\n","12          Pacific     int64           0           0.0\n","13          Rampart     int64           0           0.0\n","14        Southeast     int64           0           0.0\n","15        Southwest     int64           0           0.0\n","16          Topanga     int64           0           0.0\n","17         Van_Nuys     int64           0           0.0\n","18          West_LA     int64           0           0.0\n","19      West_Valley     int64           0           0.0\n","20         Wilshire     int64           0           0.0\n","21        Afternoon     int64           0           0.0\n","22          Evening     int64           0           0.0\n","23          Morning     int64           0           0.0\n","24            Night     int64           0           0.0\n","25            Alley     int64           0           0.0\n","26         Driveway     int64           0           0.0\n","27  Park_Playground     int64           0           0.0\n","28      Parking_Lot     int64           0           0.0\n","29         Sidewalk     int64           0           0.0\n","30           Street     int64           0           0.0\n","31       Vacant_Lot     int64           0           0.0\n","32         Vict_Age     int64           0           0.0\n","33            Month     int64           0           0.0\n","34       Crime_Code     int64           0           0.0\n","35           Gender     int64           0           0.0"],"text/html":["\n","  <div id=\"df-a3b2b3dc-1fb3-43f2-93c6-5179ad9fb23b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Column/Variable</th>\n","      <th>Data Type</th>\n","      <th># of Nulls</th>\n","      <th>Percent Null</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>77th_Street</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Central</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Devonshire</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Foothill</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harbor</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Hollenbeck</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Hollywood</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Mission</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>N_Hollywood</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Newton</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Northeast</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Olympic</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Pacific</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Rampart</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Southeast</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Southwest</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Topanga</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Van_Nuys</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>West_LA</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>West_Valley</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Wilshire</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Afternoon</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Evening</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Morning</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Night</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Alley</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Driveway</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Park_Playground</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Parking_Lot</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Sidewalk</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Street</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Vacant_Lot</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Vict_Age</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Month</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Crime_Code</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Gender</td>\n","      <td>int64</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3b2b3dc-1fb3-43f2-93c6-5179ad9fb23b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a3b2b3dc-1fb3-43f2-93c6-5179ad9fb23b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a3b2b3dc-1fb3-43f2-93c6-5179ad9fb23b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["# run the python file for checking data types again \n","# this time, for the development set\n","data_types(df_prep)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1658776793874,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"2WqMh3rZWdvP","outputId":"4aa5f700-662e-4dee-ce9e-a7585bedb17d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(42072, 36)"]},"metadata":{},"execution_count":17}],"source":["df_prep = df_prep.copy()\n","df_prep.shape"]},{"cell_type":"markdown","metadata":{"id":"K6ANW9uXWYUx"},"source":["## Train-Test-Validation Split\n","\n","The data is split into a fifty percent development (training and validation) and fifty percent holdout (testing) sets, respectively, saving 3 separate files to the data folder path. "]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1658776793876,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"kxtp-ZIjYt01","outputId":"42a3bb00-c9c3-452f-b020-59173beca26b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training size: 21036\n","Validation size: 10518\n","Test size: 10518\n","Total size: 42072 \n","\n","Training percentage: 0.5\n","Validation percentage: 0.25\n","Test percentage: 0.25\n","Total percentage: 100.0\n"]}],"source":["# Divide train set by 50%, valid set by 25%, and test set 25%\n","\n","rstate = 222\n","train_prop = 0.50\n","valid_prop = 0.25\n","test_prop = 0.25\n","size_train = np.int64(round(train_prop*len(df_prep),2))\n","size_valid = np.int64(round(valid_prop*len(df_prep),2))\n","size_test = np.int64(round(test_prop*len(df_prep),2))\n","size_total = size_test + size_valid + size_train\n","\n","# split the data into the development (train and validation)\n","# and test set, respectively\n","train, test = train_test_split(df_prep, train_size=size_train,\\\n","                              random_state=rstate)\n","valid, test = train_test_split(test, train_size=size_valid,\\\n","                              random_state=rstate)\n","\n","print('Training size:', size_train)\n","print('Validation size:', size_valid)\n","print('Test size:', size_test)\n","print('Total size:', size_train + size_valid + size_test, '\\n')\n","print('Training percentage:', round(size_train/(size_total),2))\n","print('Validation percentage:', round(size_valid/(size_total),2))\n","print('Test percentage:', round(size_test/(size_total),2))\n","print('Total percentage:', (size_train/size_total + size_valid/size_total \\\n","                          + size_test/size_total)*100)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1658776793877,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"z1Mcls3fnwxF"},"outputs":[],"source":["# subset the development and test sets into their own respective dataframes\n","train_set = train\n","valid_set = valid\n","test_set = test\n","\n","# create a copy of the train set with an appended column for age_bins\n","eda_set = train_set.copy()"]},{"cell_type":"markdown","metadata":{"id":"Zde8CIPxrqqw"},"source":["## Write Out the Train, Validation, and Test Sets to Separate .CSV Files"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":553,"status":"ok","timestamp":1658776794405,"user":{"displayName":"Leonid Shpaner","userId":"10226027130831758558"},"user_tz":420},"id":"x0s-BAxDovSm"},"outputs":[],"source":["# write out the train, validation, and test sets to .csv files to the data folder\n","# such that they are contained in their own unique files\n","# the train and validation sets can be used without prejudice. However, the data\n","# can ONLY be run on the test set once\n","train_set.to_csv(data_path2 + '/train_set.csv')\n","valid_set.to_csv(data_path2 + '/valid_set.csv')\n","test_set.to_csv(data_path2 + '/test_set.csv')\n","\n","# dataframe for exploring data part 2\n","eda_set.to_csv(data_path2 + '/eda_set.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"data_preparation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}